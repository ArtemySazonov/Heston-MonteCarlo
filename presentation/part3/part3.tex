\subsection{About Andersen's Article}
\subsection{Quadratic-Exponential Discretization Scheme}
    \begin{frame}{Quadratic-Exponential Discretization Scheme}{}\label{frame:Andersen:denotemeanstd}
        We denote 
        \begin{align}
            m    &= \E\left[\left.\hat{V}(t+\Delta)\right| \hat{V}(t)\right], \\
            s^2  &= \E\left[\left.\left(\hat{V}(t+\Delta) - m\right)^2\right| \hat{V}(t)\right], \\
            \psi &= \frac{s^2}{m^2}.
        \end{align}
    \end{frame}

    \begin{frame}{Quadratic-Exponential Discretization Scheme}{Idea}
        Andersen proposes an approximation based on moment-matching techniques. His goal is then to speed up the first step of Broadie and Kaya's method.
        He observes that the conditional distribution of $\hat{V}(t+\Delta)$ given $\hat{V}(t)$ visually difers when $\hat{V}(t)$ is small or large (in the variation coefficient sense).
        The scheme is constructed from the following two subschemes:
        \begin{enumerate}
            \item Quadratic sampling scheme ($\psi \leq 2$);
            \item Exponential sampling scheme ($\psi \geq 1$).
        \end{enumerate}
        Fortunately, these two intervals cover the whole positive real line. Furthermore, these two schemes could be applied at the same time when $\psi\in[1, 2]$. This implicates that there exist some critical value $\psi_{\text{crit}}\in[1, 2]$, which could be an indicator of which scheme is more applicable at the given value of $\psi$. Let us show you this.
    \end{frame}

    \begin{frame}{Quadratic-Exponential Discretization Scheme}{Quadratic case}
        For large enough $\hat{V}(t)$ we can approximate the distribution of $\hat{V}(t+\Delta)$ by the scaled non-central chi-squared distribution with $1$ degree of freedom:
        \begin{align}
            \law\left(\left.\hat{V}(t+\Delta) \right| \hat V(t)\right) =  a(\Delta, \hat{V}(t), VP) \chi'^2_1(b(\Delta, \hat{V}(t), VP)),
        \end{align}
        where $VP$ is the vector of parameters of the CIR variance.
        However, if $\hat{V}(t)$ is close to zero, then we have a problem in finding such $a = a(\Delta, \hat{V}(t), VP)$ and $b = b(\Delta, \hat{V}(t), VP)$ such that the moments of the desired conditional distribution could be properly matched.
    \end{frame}

    \begin{frame}{Quadratic-Exponential Discretization Scheme}{Exponential case}
        Therefore, we approximate the desired distribution with the following method. Let $\xi$ and $\eta$ be independent random variables and  $\xi \sim Be(1-p)$, $\eta \sim Exp(\beta)$ for some $p \in (0, 1)$ and $\beta > 0$. Then we have (given $\hat{V}(t)$)
        \begin{equation}
            \hat{V}(t+\Delta) = \xi\cdot\eta.
        \end{equation}
        Sampling $\xi$ and $\eta$: Smirnov's transform. Or we can use the Smirnov transform with the cdf of the desired distribution.
    \end{frame}

\subsection{Truncated Gaussian Discretization Scheme}
    \begin{frame}{Truncated Gaussian Discretization Scheme}{Idea}
        \begin{block}{Andersen:}
            \emph{In this scheme the idea is to sample from a moment-matched Gaussian density where all probability
            mass below zero is inserted into a delta-function at the origin.}
        \end{block} 
        Same, but in the formular form:
        \begin{equation}
            \left(\left.\hat{V}(t+\Delta)\right| V(t)\right) = \left(\mu + \sigma Z\right)^+,
        \end{equation}
        where $Z$ is a standard normal random variable and $\mu$ and $\sigma$ are the 'mean' and the 'standard deviation' of the desired distribution.
        We find $\mu$ and $\sigma$ from the same old moment-matching techniques (see Slide \ref{frame:Andersen:denotemeanstd}).
    \end{frame}